{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:24:15.690595Z",
     "start_time": "2024-09-13T16:24:15.594296Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from mesa import Mesa\n",
    "import argparse\n",
    "from utils import Rater, load_dataset\n",
    "from sklearn.tree import *\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Mesa Arguments')\n",
    "parser.add_argument('--env-name', default=\"MESA-SAC\")\n",
    "\n",
    "# SAC arguments\n",
    "parser.add_argument('--policy', default=\"Gaussian\",\n",
    "                    help='Policy Type: Gaussian | Deterministic (default: Gaussian)')\n",
    "parser.add_argument('--eval', type=bool, default=True,\n",
    "                    help='Evaluates a policy every 10 episode (default: True)')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor for reward (default: 0.99)')\n",
    "parser.add_argument('--tau', type=float, default=0.01, metavar='G',\n",
    "                    help='target smoothing coefficient(τ) (default: 0.01)')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='G',\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--lr_decay_steps', type=int, default=10, metavar='N',\n",
    "                    help='step_size of StepLR learning rate decay scheduler (default: 10)')\n",
    "parser.add_argument('--lr_decay_gamma', type=float, default=0.99, metavar='N',\n",
    "                    help='gamma of StepLR learning rate decay scheduler (default: 0.99)')\n",
    "parser.add_argument('--alpha', type=float, default=0.1, metavar='G',\n",
    "                    help='Temperature parameter α determines the relative importance of the entropy\\\n",
    "                            term against the reward (default: 0.1)')\n",
    "parser.add_argument('--automatic_entropy_tuning', type=bool, default=False, metavar='G',\n",
    "                    help='Automaically adjust α (default: False)')\n",
    "parser.add_argument('--seed', type=int, default=None, metavar='N',\n",
    "                    help='random seed (default: None)')\n",
    "parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                    help='batch size (default: 64)')\n",
    "parser.add_argument('--hidden_size', type=int, default=50, metavar='N',\n",
    "                    help='hidden size (default: 50)')\n",
    "parser.add_argument('--updates_per_step', type=int, default=1, metavar='N',\n",
    "                    help='model updates per simul|ator step (default: 1)')\n",
    "parser.add_argument('--update_steps', type=int, default=1000, metavar='N',\n",
    "                    help='maximum number of steps (default: 1000)')\n",
    "parser.add_argument('--start_steps', type=int, default=500, metavar='N',\n",
    "                    help='Steps sampling random actions (default: 500)')\n",
    "parser.add_argument('--target_update_interval', type=int, default=1, metavar='N',\n",
    "                    help='Value target update per no. of updates per step (default: 1)')\n",
    "parser.add_argument('--replay_size', type=int, default=1000, metavar='N',\n",
    "                    help='size of replay buffer (default: 1000)')\n",
    "parser.add_argument('--cuda', action=\"store_true\", default=False,\n",
    "                    help='run on CUDA (default: False)')\n",
    "\n",
    "# MESA arguments\n",
    "parser.add_argument('--dataset', type=str, default='Mammo', metavar='N',\n",
    "                    help='the dataset used for meta-training (default: Mammo)')\n",
    "parser.add_argument('--metric', type=str, default='aucprc', metavar='N',\n",
    "                    help='the metric used for evaluate (default: aucprc)')\n",
    "parser.add_argument('--reward_coefficient', type=float, default=100, metavar='N')\n",
    "parser.add_argument('--num_bins', type=int, default=5, metavar='N', \n",
    "                    help='number of bins (default: 5). state-size = 2 * num_bins.')\n",
    "parser.add_argument('--sigma', type=float, default=0.2, metavar='N', \n",
    "                    help='sigma of the Gaussian function used in meta-sampling (default: 0.2)')\n",
    "parser.add_argument('--max_estimators', type=int, default=10, metavar='N',\n",
    "                    help='maximum number of base estimators in each meta-training episode (default: 10)')\n",
    "parser.add_argument('--meta_verbose', type=int, default=10, metavar='N',\n",
    "                    help='number of episodes between verbose outputs. \\\n",
    "                    If \\'full\\' print log for each base estimator (default: 10)')\n",
    "parser.add_argument('--meta_verbose_mean_episodes', type=int, default=25, metavar='N',\n",
    "                    help='number of episodes used for compute latest mean score in verbose outputs.')\n",
    "parser.add_argument('--verbose', type=bool, default=False, metavar='N',\n",
    "                    help='enable verbose when ensemble fit (default: False)')\n",
    "parser.add_argument('--random_state', type=int, default=None, metavar='N', \n",
    "                    help='random_state (default: None)')\n",
    "parser.add_argument('--train_ir', type=float, default=1, metavar='N', \n",
    "                    help='imbalance ratio of the training set after meta-sampling (default: 1)')\n",
    "parser.add_argument('--train_ratio', type=float, default=1, metavar='N', \n",
    "                    help='the ratio of the data used in meta-training. \\\n",
    "                    set train_ratio<1 to use a random subset for meta-training (default: 1)')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmesa\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Mesa\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01margparse\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Rater, load_dataset\n",
      "File \u001B[0;32m~/Documents/GitHub/mesa/mesa.py:9\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mCreated on Sat Feb  8 02:27:20 2020\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m@author: ZhiningLiu1998\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mmailto: zhining.liu@outlook.com / v-zhinli@microsoft.com\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:25:57.558162Z",
     "start_time": "2024-09-13T16:25:57.555385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "\n",
    "# 输出当前时间\n",
    "print(\"当前时间:\", current_time, flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前时间: 2024-09-14 00:25:57.556428\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization and meta-training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:24:27.028269Z",
     "start_time": "2024-09-13T16:24:27.011812Z"
    }
   },
   "source": [
    "''' Prepare the Environment '''\n",
    "\n",
    "#  load dataset\n",
    "dataset = 'Mammo'\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_dataset(dataset)\n",
    "print(\"type of X_train: \", type(X_train))\n",
    "print(\"type of y_train: \", type(y_train))\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_valid shape: \", X_valid.shape)\n",
    "estimator, base_estimator = 'DT', DecisionTreeClassifier(max_depth=None)\n",
    "args = parser.parse_args([])\n",
    "n_estimators = args.max_estimators\n",
    "\n",
    "# plot the class distribution\n",
    "def plot_class_distribution(ax, labels, title):\n",
    "    sns.countplot(data=pd.DataFrame(labels, columns=['Class']), x='Class', ax=ax)\n",
    "    ax.set(title=title)\n",
    "   \n",
    "sns.set(style='whitegrid')\n",
    "sns.set_context('talk', font_scale=1)\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plot_class_distribution( \n",
    "    ax = ax, \n",
    "    labels = np.concatenate([y_train, y_valid, y_test]),\n",
    "    title = f'{dataset} dataset class distribution')\n",
    "plt.tight_layout(pad=1.8)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#  load dataset\u001B[39;00m\n\u001B[1;32m      4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMammo\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m X_train, y_train, X_valid, y_valid, X_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m(dataset)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype of X_train: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mtype\u001B[39m(X_train))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype of y_train: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mtype\u001B[39m(y_train))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:24:34.122425Z",
     "start_time": "2024-09-13T16:24:34.107678Z"
    }
   },
   "source": [
    "''' Meta-training '''\n",
    "\n",
    "# initialize MESA\n",
    "print ('Dataset: {}'.format(dataset))\n",
    "mesa = Mesa(\n",
    "    args=args, \n",
    "    base_estimator=base_estimator, \n",
    "    n_estimators=args.max_estimators)\n",
    "\n",
    "# start meta-training\n",
    "print ('Start meta-training of MESA ... ...')\n",
    "start_time = time.clock()\n",
    "mesa.meta_fit(X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "end_time = time.clock()\n",
    "print ('Meta-training time: {:.3f} s'.format(end_time - start_time))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Mammo\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Mesa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# initialize MESA\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataset: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(dataset))\n\u001B[0;32m----> 5\u001B[0m mesa \u001B[38;5;241m=\u001B[39m \u001B[43mMesa\u001B[49m(\n\u001B[1;32m      6\u001B[0m     args\u001B[38;5;241m=\u001B[39margs, \n\u001B[1;32m      7\u001B[0m     base_estimator\u001B[38;5;241m=\u001B[39mbase_estimator, \n\u001B[1;32m      8\u001B[0m     n_estimators\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mmax_estimators)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# start meta-training\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStart meta-training of MESA ... ...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Mesa' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the meta-training process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:48:41.608265Z",
     "start_time": "2024-09-12T03:48:41.404472Z"
    }
   },
   "source": [
    "def slide_mean(data, window_half):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        lower_bound = max(i-window_half, 0)\n",
    "        upper_bound = min(i+window_half+1, len(data)-1)\n",
    "        result.append(np.mean(data[lower_bound:upper_bound]))\n",
    "    return result\n",
    "\n",
    "slide_window_half = 25\n",
    "df_scores = pd.DataFrame(mesa.scores, columns=['Training', 'Validation', 'Test'])\n",
    "\n",
    "sns.set(style='ticks')\n",
    "sns.set_context('talk', font_scale=0.7)\n",
    "fig = plt.figure(figsize=(12, 3.5))\n",
    "for i in range(df_scores.shape[1]):\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    column = df_scores.columns[i]\n",
    "    view = pd.Series(slide_mean(df_scores[column], slide_window_half))\n",
    "    sns.lineplot(data=view, ax=ax)\n",
    "    start_steps = args.start_steps / args.max_estimators\n",
    "    ax.vlines(start_steps, view.min(), view.max(), color=\"orange\", linestyles='dashed', linewidth=3)\n",
    "    ax.text(start_steps, \n",
    "            (view.min() + view.max()) / 2, \n",
    "            'Start meta-training', \n",
    "            rotation=90, ha='center', va='center', fontsize=12)\n",
    "    ax.set(title=f'{dataset} {column}', \n",
    "           xlabel='# Meta-training episodes', \n",
    "           ylabel=f'{column} AUCPRC')    \n",
    "    ax.grid(axis='y')\n",
    "\n",
    "# fig.suptitle(f'Meta-training on {dataset} dataset')\n",
    "plt.tight_layout(pad=1.8)\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with other resampling baselines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:50:47.170023Z",
     "start_time": "2024-09-12T03:49:59.988918Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from baselines.canonical_resampling import Resample_classifier\n",
    "\n",
    "def evaluate(clf, X_train, y_train, X_valid, y_valid, X_test, y_test, rater):\n",
    "    score_train = rater.score(y_train, clf.predict_proba(X_train)[:,1])\n",
    "    score_valid = rater.score(y_valid, clf.predict_proba(X_valid)[:,1])\n",
    "    score_test = rater.score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return [score_train, score_valid, score_test]\n",
    "\n",
    "def stratifiedKFoldTest(clf, clf_name, X, y, X_valid, y_valid, rater,\n",
    "                        n_splits=4, repeat=1, random_state=None):\n",
    "    scores_list, time_list = [], []\n",
    "    for i_repeat in range(repeat):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, random_state=random_state)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            start_time = time.clock()\n",
    "            if clf_name[:4] == 'MESA':\n",
    "                clf.fit(X_train, y_train, X_valid, y_valid, verbose=False)\n",
    "            else:\n",
    "                clf.fit(X_train, y_train)\n",
    "            end_time = time.clock()\n",
    "            time_list.append(end_time - start_time)\n",
    "            scores = evaluate(clf, X_train, y_train, X_valid, y_valid, X_test, y_test, rater)\n",
    "            scores_list.append(scores)\n",
    "    return scores_list, time_list\n",
    "\n",
    "cv_params = {\n",
    "    'X': np.concatenate([X_train, X_test]),\n",
    "    'y': np.concatenate([y_train, y_test]),\n",
    "    'X_valid': X_valid,\n",
    "    'y_valid': y_valid,\n",
    "    'rater': Rater('aucprc'),\n",
    "    'n_splits': 4,\n",
    "    'repeat': 10,\n",
    "}\n",
    "    \n",
    "resample_names = ['ORG', 'RUS', 'NM', 'NCR', 'ENN', \n",
    "    'Tomek', 'ALLKNN', 'OSS',  'ROS', 'SMOTE', 'ADASYN', \n",
    "    'BorderSMOTE', 'SMOTEENN', 'SMOTETomek']\n",
    "resample_clf_list = [Resample_classifier(resample_by=method) for method in resample_names]\n",
    "\n",
    "def copyMesa(mesa, n_estimators=None):\n",
    "    mesa_copy = deepcopy(mesa)\n",
    "    if n_estimators is not None:\n",
    "        mesa_copy.n_estimators = n_estimators\n",
    "    return mesa_copy\n",
    "\n",
    "from datetime import datetime\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "# 输出当前时间\n",
    "print(\"当前时间:\", current_time)\n",
    "\n",
    "\n",
    "ensemble_size_list = [20, 10, 5]\n",
    "clf_names = [f'MESA (k={size})' for size in ensemble_size_list] + resample_names\n",
    "clf_list = [copyMesa(mesa, size) for size in ensemble_size_list] + resample_clf_list\n",
    "\n",
    "df_results_list = []\n",
    "for (clf, clf_name) in zip(clf_list, clf_names):\n",
    "    scores_list, time_list = stratifiedKFoldTest(clf, clf_name, **cv_params)\n",
    "    df_results = pd.DataFrame(scores_list, columns=['train', 'valid', 'test'])\n",
    "    df_results['time'] = time_list\n",
    "    df_results['method'] = clf_name\n",
    "    df_results_list.append(df_results)\n",
    "    info = '{:<12s} |'.format(clf_name)\n",
    "    for column in ['train', 'valid', 'test']:\n",
    "        info += ' {} {:.3f}-{:.3f} |'.format(\n",
    "            column, df_results.mean()[column], df_results.std()[column])\n",
    "    info += ' {}-fold CV ({} runs) | ave run time: {:.2f}s'.format(\n",
    "        cv_params['n_splits'], cv_params['repeat'], np.mean(time_list))\n",
    "    print (info)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:50:47.589969Z",
     "start_time": "2024-09-12T03:50:47.174579Z"
    }
   },
   "source": [
    "# visualize the performance with error bar\n",
    "df_results_all = pd.concat(df_results_list)\n",
    "order_performance = df_results_all.groupby('method').mean()['test'].sort_values(ascending=False).index.tolist()\n",
    "order_runtime = df_results_all.groupby('method').mean()['time'].sort_values(ascending=True).index.tolist()\n",
    "\n",
    "order_performance = order_runtime = clf_names\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 8))\n",
    "sns.set(style='whitegrid')\n",
    "sns.set_context('talk', font_scale=1)\n",
    "# ax = sns.barplot(x='test', y='method', data=df_results_all, ci=\"sd\", capsize=.2, order=order)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "sns.stripplot(x='test', y='method', data=df_results_all, order=order_performance, size=4, color=\".3\", ax=ax1)\n",
    "sns.boxplot(x='test', y='method', data=df_results_all, order=order_performance, ax=ax1)\n",
    "ax1.set(xlabel='Test AUCPRC', ylabel='Method')\n",
    "sns.stripplot(x='time', y='method', data=df_results_all, order=order_runtime, size=4, color=\".3\", ax=ax2)\n",
    "sns.boxplot(x='time', y='method', data=df_results_all, order=order_runtime, ax=ax2)\n",
    "ax2.set(xlabel='Run Time', ylabel='Method')\n",
    "\n",
    "fig.suptitle('Results in {} task ({}-fold stratified CV, {} independent runs)'.format(dataset, cv_params['n_splits'], cv_params['repeat']), y=1.05)\n",
    "plt.xlim(0,)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
